================================================================================
        CHAPTER 4: METHODOLOGY - AGENTIC FAKE NEWS DETECTION SYSTEM
================================================================================
                           Sinhala Fake News Detection Project
                                   December 2024
================================================================================

4.1 SYSTEM ARCHITECTURE OVERVIEW
================================

The proposed solution implements a novel "Two-Stage Agentic Pipeline" for
automated fact-checking. Unlike traditional classifiers that output a simple
probability score (0-1), this system mimics the workflow of a human
fact-checker.

The architecture consists of two specialized AI agents working in tandem:

[USER CLAIM]
     ⬇
[CLAIM DECOMPOSER] (Preprocessing)
     ⬇
[STAGE 1: RESEARCH AGENT] ───→ [Tools: Web Search, Vector DB]
     ⬇ (Outputs Structured Evidence JSON)
[STAGE 2: JUDGE AGENT]
     ⬇ (Outputs Final Verdict & Explanation)
[FINAL VERDICT] (Sinhala Explanation + Citations)


4.1.1 Rationale for Agentic Approach
------------------------------------
Traditional NLP models (like BERT) treat fact-checking as a text classification
problem. This fails for "context-dependent" fake news because:
1. They lack access to real-time information (knowledge cutoffs)
2. They cannot verify new events
3. They hallucinate facts

My agentic approach solves this by:
1. Separating "Evidence Gathering" from "Decision Making"
2. Enabling access to live internet data
3. Enforcing citation rules


4.2 CLAIM PREPROCESSING & DECOMPOSITION
=======================================

Before verification, the raw user input undergoes preprocessing by the
`ClaimDecomposer` module.

4.2.1 Component Identification
------------------------------
The system breaks down the claim into:
- KEYWORDS: Significant nouns for search queries (e.g., "IMF", "Fuel Price")
- TEMPORAL TYPE: Is this "Recent" (requires web search) or "Historical"?
- ENTITIES: Who/What is being discussed

Code Implementation (ClaimDecomposer):
```python
keywords = self._extract_keywords(claim)
temporal_type = self._get_temporal_type(claim, years)
vector_query = self._create_vector_query(claim, keywords)
```

4.2.2 Language Normalization
----------------------------
Sinhala is a morphologically rich language. The system handles:
- Mixed Language (Singlish): "Petrol price adu wela" → Translated to English/Sinhala
- Pure Sinhala: Used as-is for local search
- English: Translated to Sinhala for user reporting

This ensures the system can handle queries like "Colombo port city eka wikunuwada?"
effectively.


4.3 STAGE 1: THE RESEARCH AGENT (EVIDENCE GATHERER)
===================================================

The Research Agent is the "Investigator". Its sole job is to find facts.
It has NO opinion and makes NO verdicts.

4.3.1 Role & Responsibilities
-----------------------------
- Search the internet (Google/DuckDuckGo) for relevant news
- Search the Vector Database (Pinecone) for similar past claims
- Read and extract snippets from 4-5 diverse sources
- Label evidence as "SUPPORTS" or "REFUTES"

4.3.2 System Prompt Design
--------------------------
The Research Agent is powered by a rigorous system prompt designed to prevent
hallucination:

> "Your ONLY job is to gather and structure evidence...
> You will NOT give a verdict...
> CRITICAL RULE - DO NOT ALTER THE CLAIM...
> For each result, extract 1-3 short snippets..."

4.3.3 Evidence Object Structure
-------------------------------
The output of Stage 1 is a structured JSON, NOT text.
This ensures Stage 2 receives clean machine-readable data.

Structure:
```json
{
  "claim_original": "Fuel prices will increase by Rs 50",
  "evidence": [
    {
      "source": "Lankadeepa",
      "relation": "SUPPORTS",
      "snippet": "Minister says price hike inevitable...",
      "credibility": "high"
    },
    {
      "source": "Twitter User",
      "relation": "REFUTES",
      "snippet": "Fake news alert...",
      "credibility": "low"
    }
  ]
}
```


4.4 STAGE 2: THE JUDGE AGENT (VERDICT GENERATOR)
================================================

The Judge Agent is the "Decision Maker". It acts like a judge in a court
who reviews evidence provided by the investigator.

4.4.1 Role & Responsibilities
-----------------------------
- Review the JSON evidence provided by the Research Agent
- Weigh the credibility of sources (Official > Social Media)
- Determine the final verdict (TRUE, FALSE, MISLEADING, NEEDS_VERIFICATION)
- Write a natural language explanation in Sinhala
- Add inline citations [1][2]

4.4.2 Decision Logic
--------------------
The Judge Agent uses the following logic (enforced via prompt):

- TRUE: Multiple high-credibility sources SUPPORT the claim.
- FALSE: Multiple high-credibility sources REFUTE the claim.
- MISLEADING: Evidence shows the claim is technically true but missing context.
- NEEDS_VERIFICATION: Evidence is conflicting or insufficient.

4.4.3 Generating Sinhala Explanations
-------------------------------------
Instead of a simple "FALSE" label, the system generates a detailed explanation:

Example Input: "Police arrested 5 students."
Verdict:
"මෙම පුවත සත්‍ය වේ. ලංකාදීප සහ හිරු ප්‍රවෘත්ති වාර්තා කරන පරිදි [1][2],
අරගලය අතරතුර විශ්වවිද්‍යාල සිසුන් 5 දෙනෙකු අත්අඩංගුවට ගෙන ඇත.
පොලිස් මාධ්‍ය ප්‍රකාශක මෙය තහවුරු කරයි [3]."

This provides transparency and teaches media literacy to the user.


4.5 HYBRID VERIFICATION STRATEGY
================================

The system uses a "Hybrid" approach to finding information:

1. Vector Database (Pinecone):
   - Fast retrieval (milliseconds)
   - Good for: Debunking known fake news that re-appears
   - Contains: 5,000+ previously verified articles

2. Live Web Search (DeepResearch):
   - Real-time retrieval
   - Good for: Breaking news and new rumors
   - Contains: Entire internet

The Verdict Agent combines these:
IF (High Similarity Match in DB) -> Use DB Evidence
ELSE -> Trigger Web Research


4.6 TECHNOLOGY STACK IMPLEMENTATION
===================================

4.6.1 Large Language Model (LLM)
--------------------------------
- Model: Alibaba Tongyi DeepResearch (via OpenRouter)
- Size: ~30 Billion Parameters
- Why this model?
  - Specialized for "Research" tasks (browsing, summarizing)
  - Excellent Sinhala language understanding
  - Cost-effective compared to GPT-4

4.6.2 Vector Database
---------------------
- Provider: Pinecone (Serverless)
- Dimensions: 1024 (multilingual-e5-large model)
- Metric: Cosine Similarity

4.6.3 Backend API
-----------------
- Framework: FastAPI (Python)
- Features: Asynchronous task processing, caching with Redis
- Deployment: Render.com (Cloud)

4.6.4 Frontend
-----------------
- Technology: Vanilla HTML/JS with Tailwind (for lightweight speed)
- Features: Real-time streaming of Research steps (Search -> Read -> Verdict)


================================================================================
4.7 FLOWCHART OF THE VERIFICATION PROCESS
================================================================================

1. USER INPUT: "Tomorrow is a public holiday"

2. PREPROCESSING:
   - Language: English -> Sinhala context
   - Type: "Future/Prediction"

3. RESEARCH AGENT:
   - Queries: "Public holiday tomorrow Sri Lanka gazette"
   - Finds: Govt Gazette (No), News First (No reporting)
   - Output: Evidence list (Refutes)

4. JUDGE AGENT:
   - Analyzes: "Official sources do not mention a holiday."
   - Reasoning: "Lack of official gazette means false."
   - Drafts: Sinhala explanation.

5. FINAL OUTPUT:
   - Label: FALSE
   - Text: "හෙට රජයේ නිවාඩු දිනයක් නොවේ..."
   - Sources: [Gazette.lk, NewsFirst]
