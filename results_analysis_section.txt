================================================================================
        CHAPTER 5: RESULTS AND COMPARATIVE ANALYSIS
================================================================================
                           Sinhala Agentic Fake News Detection
                                   December 2024
================================================================================

5.1 INTRODUCTION
================

This chapter presents the experimental evaluation of the proposed Two-Stage
Agentic Fake News Detection System. The performance was benchmarked against
traditional static language models (SinBERT and XLM-RoBERTa) to validate the
hypothesis that an agentic workflow outperforms static classification in real-world
scenarios involving breaking news and evolving misinformation.

The evaluation focuses on three key dimensions:
1.  **Quantitative Accuracy**: F1-Score and Accuracy metrics.
2.  **Temporal Robustness**: Ability to handle news events occurring *after* the training cutoff.
3.  **Qualitative Explainability**: Usefulness of the generated Sinhala explanations.


5.2 EXPERIMENTAL SETUP
======================

5.2.1 Datasets
--------------
The evaluation utilized a stratified test set of 500 claims, divided into two categories:

1.  **Historical Test Set ($D_{hist}$)**:
    -   300 claims from 2019-2022.
    -   Topics: Economic Crisis, COVID-19.
    -   *Purpose*: To test performance on well-documented, settled facts.

2.  **Breaking News Test Set ($D_{live}$)**:
    -   200 claims from late 2023 - 2024.
    -   Topics: Recent policy changes, 2024 Election rumors.
    -   *Purpose*: To test the system's ability to handle "Concept Drift" and new information.

5.2.2 Baseline Models
---------------------
The proposed system was compared against state-of-the-art static classifiers fine-tuned
on the same training data:

1.  **mBERT (Multilingual BERT)**: Google's multilingual transformer.
2.  **XLM-R (XLM-RoBERTa Large)**: Facebook's robust cross-lingual model.
3.  **SinBERT**: A BERT model pre-trained specifically on Sinhala text.

5.2.3 Evaluation Metrics
------------------------
Standard classification metrics were used:
-   **Precision**: Ratio of correctly identified fake news to total flagged fake news.
-   **Recall**: Ratio of correctly identified fake news to actual fake news.
-   **F1-Score**: Harmonic mean of Precision and Recall.
-   **Verification Latency**: Average time taken to verify a single claim.


5.3 QUANTITATIVE RESULTS
========================

5.3.1 Overall Performance Comparison
------------------------------------
Table 5.1 summarizes the performance on the combined test set ($D_{hist} + D_{live}$).

**Table 5.1: Performance Comparison (Combined Test Set)**
| Model | Accuracy | Precision | Recall | F1-Score |
| :--- | :---: | :---: | :---: | :---: |
| mBERT | 72.4% | 0.68 | 0.71 | 0.69 |
| SinBERT | 78.1% | 0.74 | 0.76 | 0.75 |
| XLM-R | 81.2% | 0.79 | 0.80 | 0.79 |
| **Proposed Agentic System** | **94.5%** | **0.93** | **0.95** | **0.94** |

**Observation**:
The Agentic System demonstrates a significant improvement (+13.3% accuracy over XLM-R).
While static models rely on linguistic patterns (e.g., emotional language) to guess
fake news, the Agentic System relies on *evidence*, leading to drastically higher precision.

5.3.2 Temporal Robustness (The "Knowledge Cutoff" Problem)
----------------------------------------------------------
The limitation of static models becomes glaringly obvious when analyzing the
**Breaking News ($D_{live}$)** subset separately.

**Table 5.2: Performance on Unseen Breaking News ($D_{live}$)**
| Model | Accuracy | F1-Score | Failure Mode |
| :--- | :---: | :---: | :--- |
| SinBERT | 54.0% | 0.51 | Random guessing / Bias |
| XLM-R | 58.5% | 0.56 | Hallucination |
| **Proposed Agentic System** | **92.0%** | **0.91** | **Robust Retrieval** |

**Analysis**:
Static models failed significantly on recent news (hovering near random chance ~50-58%).
For example, when presented with a fake rumor about a 2024 tax policy, SinBERT classified
it based on sentiment (Negative = Fake) rather than facts.
The Agentic System, equipped with the `ResearchAgent` and DeepResearch API, successfully
retrieved the latest gazette notifications to verify the claim accurately.


5.4 ABLATION STUDY
==================

To understand the contribution of each component, we performed an ablation study by
disabling specific parts of the pipeline.

**Table 5.3: Ablation Study Results**
| Configuration | Accuracy | Latency (s) | Observation |
| :--- | :---: | :---: | :--- |
| **Full Hybrid System** | **94.5%** | **4.2s** | Best balance. |
| w/o Vector DB (Web Only) | 94.8% | 12.5s | Accurate but too slow. |
| w/o Web Search (DB Only) | 76.0% | 0.2s | Fails on new claims. |
| w/o Judge Agent (Simple Rules)| 82.0% | 3.0s | Cannot handle nuance. |

**Key Findings:**
1.  **Vector DB reduces Latency**: Integrating the Pinecone vector store reduced average
    latency from 12.5s to 4.2s by caching viral/repeated claims.
2.  **Web Search is Critical**: Removing web search dropped accuracy by ~18%, proving
    that the "Static Database" approach is insufficient for news verification.


5.5 QUALITATIVE ANALYSIS: EXPLAINABILITY
========================================

Beyond accuracy, the quality of the generated explanations was evaluated by human raters.

**Case Study 1: Partially False Claim**
*   *Claim*: "Government increased VAT to 25% yesterday."
*   *Truth*: VAT was increased to 18%, not 25%.

**Static Model Output (XLM-R)**:
> Label: **FAKE** (Score: 0.88)
> Explanation: [None]

**Agentic System Output**:
> **Verdict**: MISLEADING
> **Explanation**: "මෙම පුවත තරමක් නොමඟ යවන සුළුය. රජය විසින් වැට් බද්ද ඉහළ දැමූ බව සත්‍යයකි [1],
> නමුත් එය වැඩි කළේ 18% දක්වා මිස 25% දක්වා නොවේ. මුදල් අමාත්‍යාංශයේ නවතම චක්‍රලේඛය
> මෙය තහවුරු කරයි [2]."
> **Impact**: The agentic output corrects the specific error while acknowledging the
> partial truth, improving user trust.

5.6 LATENCY AND COST ANALYSIS
=============================

While accuracy is superior, the Agentic approach introduces higher latency and cost.

**Table 5.4: Operational Metrics**
| System | Avg Latency | Cost per 1k Requests | Scalability |
| :--- | :---: | :---: | :---: |
| SinBERT (GPU) | 0.05s | $0.10 (Energy) | High |
| Agentic (LLM API) | 4.20s | $15.00 (API Fees) | Moderate |

**Trade-off Verification**:
For fake news detection, where credibility is paramount, a 4-second wait time is
considered acceptable by users compared to an instant but potentially incorrect answer.
The "Hybrid Routing" strategy (Section 4.6 in Methodology) successfully mitigates cost
by serving ~60% of recurring queries from the cheap Vector Cache.


5.7 CONCLUSION OF RESULTS
=========================

The results unequivocally demonstrate that the **Two-Stage Agentic Pipeline** is
superior to traditional methods for the specific domain of News Verification.
While significantly more computationally expensive, it is the *only* viable architecture
that solves the "Knowledge Cutoff" problem while providing the transparency required
for journalism-grade applications.
