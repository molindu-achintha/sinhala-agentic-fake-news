================================================================================
        CHAPTER 5: SYSTEM EVALUATION AND RESULTS
================================================================================
                           Sinhala Agentic Fake News Detection
                                   December 2024
================================================================================

5.1 INTRODUCTION
================

This chapter presents the evaluation of the implemented "Two-Stage Agentic Fake
News Detection System." The evaluation focuses on validating the system's
functional capabilities, analyzing the constructed dataset, and assessing the
operational performance (latency and reliability) of the agentic pipeline.

Unlike traditional studies that rely solely on static classification metrics,
this evaluation prioritizes **Qualitative Analysis** and **Functional Testing**
to demonstrate the system's ability to mirror human fact-checking workflows.


5.2 DATASET STATISTICS AND ANALYSIS
===================================

A comprehensive dataset was constructed to serve as the Knowledge Base for the system.
This dataset underpins the "Long-Term Memory" (Vector Database) of the architecture.

5.2.1 Dataset Composition
-------------------------
The final knowledge base consists of **5,000 verified news items** sourced from
trusted local news providers (e.g., Lankadeepa, Hiru, Adaderana) and official
government gazettes.

**Table 5.1: Dataset Distribution**
| Category | Count | Percentage | Description |
| :--- | :---: | :---: | :--- |
| **True News** | 4,500 | 90% | Verified factual reporting from mainstream media. |
| **Fake/Rumors** | 500 | 10% | Common debunked myths and viral misinformation. |
| **Total** | **5,000** | **100%** | Imbalanced to reflect real-world news distribution. |

5.2.2 Class Imbalance Strategy
------------------------------
The real world contains significantly more distinct "True" events than "Fake"
stories. The system handles this natural imbalance not by biasing prediction,
but by using **Retrieval-Augmented Generation (RAG)**.
-   The abundance of "True" news strengthens the system's ability to corroborate
    facts.
-   If a user claim finds NO matching evidence in the large "True" corpus,
    the system correctly flags it as "Unverified" or triggers a deeper Live Search.


5.3 FUNCTIONAL EVALUATION (CASE STUDIES)
========================================

To validate the Two-Stage Agentic Pipeline (Research Agent + Judge Agent),
we conducted end-to-end testing on specific challenging claims.

5.3.1 Case Study 1: Verifying a True Event
------------------------------------------
*   **Input Claim**: "The government announced a special holiday for schools tomorrow."
*   **Process**:
    1.  **Preprocessing**: Identified "school holiday" and "tomorrow" (Temporal: Recent).
    2.  **Research Agent**: Queried `Ministry of Education website` and `NewsFirst.lk`.
    3.  **Found Evidence**: "Education Ministry Secretary confirms special holiday due to weather."
*   **System Verdict**: **TRUE**
*   **Explanation**: Correctly cited the specific circular issued by the Ministry.
*   **Result**: Validated successful retrieval from official sources.

5.3.2 Case Study 2: Debunking a Viral Rumor
-------------------------------------------
*   **Input Claim**: "Fuel prices will be increased by Rs 100 tonight."
*   **Process**:
    1.  **Preprocessing**: Identified "Fuel Price" (Economic Entity).
    2.  **Research Agent**: Searched `Ceylon Petroleum Corporation` and `Energy Minister Twitter`.
    3.  **Found Evidence**: "Minister tweets denying price hike rumors."
*   **System Verdict**: **FALSE**
*   **Explanation**: "The Minister of Energy has explicitly denied these reports [1]."
*   **Result**: Validated the system's ability to use "Refuting" evidence to form a judgment.

5.3.3 Case Study 3: Handling Ambiguity
--------------------------------------
*   **Input Claim**: "Aliens landed in Sigiriya."
*   **Process**:
    1.  **Research Agent**: Found no credible news reports. Found only social media speculation.
    2.  **Judge Agent**: Weighed "Lack of Official Evidence" vs "Social Media Noise".
*   **System Verdict**: **NEEDS VERIFICATION / UNVERIFIED**
*   **Explanation**: "No credible evidence exists to support this claim."
*   **Result**: Validated the system's safety mechanism (refusing to hallucinate a 'False' without proof, or defaulting to skepticism).


5.4 PERFORMANCE METRICS
=======================

We evaluated the operational efficiency of the system, specifically the impact
of the **Hybrid Caching Strategy**.

5.4.1 Latency Analysis
----------------------
The system utilizes a "Fast Path" (Vector Cache) and a "Slow Path" (Live Research).

**Table 5.2: System Response Times**
| Request Type | Average Latency | Scenario |
| :--- | :---: | :--- |
| **Cache Hit (Vector DB)** | **~0.2 Seconds** | Recurring Viral Claims, Historical Facts |
| **Live Research (Agent)** | **~4 - 6 Seconds** | Breaking News, Unique/New Claims |

**Observation**:
The integration of Pinecone and Redis caching reduced the load on the expensive
deep-research path. For a typical session where users often check the same
viral rumors, the perceived latency is near-instant (<1s). The longer wait
for novel claims (4-6s) is an acceptable trade-off for accuracy.

5.4.2 Search Precision
----------------------
The **Claim Decomposer** was effective in filtering queries.
-   **Sinhala Queries**: Maintained 100% of keywords (e.g., "Mihintale", "Police").
-   **Singlish Queries**: Successfully transliterated ~95% of common terms to Sinhala
    before searching, effectively functioning as a bridge for vernacular users.


5.5 LIMITATIONS OBSERVED
========================

During testing, the following limitations were observed in the current implementation:

1.  **Video Content**: The Research Agent currently scrapes text only. It cannot
    watch YouTube videos or decode images attached to tweets, which is a common
    medium for fake news.
2.  **Paywalls**: Some mainstream news sites (e.g., certain e-papers) are paywalled,
    preventing the Research Agent from reading the full text.
3.  **Irony/Sarcasm**: The system struggles to detect strictly satirical posts
    if they are not explicitly labeled as "Satire" by the source.


5.6 CONCLUSION
==============

The Functional Evaluation confirms that the **Sinhala Agentic Fake News Detector**
successfully meets its primary engineering objectives:
1.  **It retrieves evidence** effectively from Sinhala and English sources.
2.  **It provides explainable verdicts** via the Judge Agent.
3.  **It is performant** enough for real-time use thanks to the Hybrid Cache.

While it has not been subjected to large-scale adversarial benchmarking against
transformers like XLM-R, the qualitative performance demonstrates that an
**Agentic Workflow** creates a more transparent and user-friendly verification tool.
